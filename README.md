Deep Learning Course @New York University

## DEEP LEARNING - IMAGE CAPTIONING: A COMPARATIVE STUDY
To be Filled 

## ATTENTION MODEL + ResNet50 
##### MODEL DESCRIPTION:

| Attention Mechanism | Vocabulary(Unique Words) |Number of Images|Training Epochs|Captions per image|Total Datapoints|Training Batch Size|
|-------------------- | -------------------------|----------------|---------------|------------------|----------------|-------------------|        
|  Bahdanau Attention | 7,000                    | 6,000          | 30            |5                 |      30,000    | 64                |

View Detailed Results     |  View Detailed Epoch Results
:-------------------------:|:-------------------------:
[Click To View](https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Attention%2BResNet%20Results/attentionResNetResults.pdf)  |  [Click To View]()

##### MODEL PERFORMANCE SUMMARY
 <p align="center">
  <img src="https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Images/model2res.png">
</p>

##### EXAMPLE: GOOD PREDICTION RESULT
 <p align="center">
  <img height="400" width="500" src="https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Attention%2BResNet%20Results/good/good2.png">
</p>

##### EXAMPLE: FAIR PREDICTION RESULT
 <p align="center">
  <img height="225" width="630" src="https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Attention%2BResNet%20Results/fair/fair2.png">
</p>

##### EXAMPLE: BAD PREDICTION RESULT
 <p align="center">
  <img height="250" width="700" src="https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Attention%2BResNet%20Results/bad/bad1.png">
</p>


## ATTENTION MODEL + InceptionV3 : 
##### MODEL PERFORMANCE SUMMARY
 <p align="center">
  <img src="https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Images/model1res.png">
</p>

### MODEL 1: 
##### MODEL DESCRIPTION:

| Attention Mechanism | Vocabulary(Unique Words) |Number of Images|Training Epochs|Captions per image|Total Datapoints|Training Batch Size|
|-------------------- | -------------------------|----------------|---------------|------------------|----------------|-------------------|        
|  Bahdanau Attention | 5,000                    | 6,000          | 10            |5                 |      30,000    | 64                |

##### PREDICTION EXAMPLE
 <p align="center">
  <img src="https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Images/predictions0.png">
</p>

View Detailed Epoch Results     |  View Folder Containing Image Results
:-------------------------:|:-------------------------:
[Click To View](https://github.com/HemanthTejaY/Image-Captioning-A-Comparative-Study/blob/main/Attention%20Results/attention-model0/epochs/attention-model-0.pdf)  |  [Click To View](https://github.com/HemanthTejaY/Image-Captioning-A-Comparative-Study/tree/main/Attention%20Results/attention-model0)

### MODEL 2: 
##### MODEL DESCRIPTION:

| Attention Mechanism | Vocabulary(Unique Words) |Number of Images|Training Epochs|Captions per image|Total Datapoints|Training Batch Size|
|-------------------- | -------------------------|----------------|---------------|------------------|----------------|-------------------|        
|  Bahdanau Attention | 7,000                    | 6,000          | 30            |5                 |    30,000      | 64                |

##### PREDICTION EXAMPLE
 <p align="center">
  <img src="https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Images/predictions1.png">
</p>

View Detailed Epoch Results     |  View Folder Containing Image Results
:-------------------------:|:-------------------------:
[Click To View](https://github.com/HemanthTejaY/Image-Captioning-A-Comparative-Study/blob/main/Attention%20Results/attention-model1/epochs/attention-model-2.pdf)  |  [Click To View](https://github.com/HemanthTejaY/Image-Captioning-A-Comparative-Study/tree/main/Attention%20Results/attention-model1)

### MODEL 3: 
##### MODEL DESCRIPTION:

| Attention Mechanism | Vocabulary(Unique Words) |Number of Images|Training Epochs|Captions per image|Total Datapoints|Training Batch Size|
|-------------------- | -------------------------|----------------|---------------|------------------|----------------|-------------------|        
|  Bahdanau Attention | 7,000                    | 10,000         | 50            |5                 |    50,000      | 64                |

##### PREDICTION EXAMPLE
 <p align="center">
  <img src="https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Images/predictions2.png">
</p>
 
View Detailed Epoch Results     |  View Folder Containing Image Results
:-------------------------:|:-------------------------:
[Click To View](https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Attention%20Results/attention-model2/epochs/attention-model-3.pdf)  |  [Click To View](https://github.com/HemanthTejaY/Deep-Learning-Image-Captioning---A-comparitive-study/blob/main/Attention%20Results/attention-model2)

## REFERENCES


